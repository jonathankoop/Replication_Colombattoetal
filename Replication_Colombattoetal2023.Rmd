---
title: 'Replication of Colombatto et al. (2023): Vaccine Nationalism Counterintuitively
  Erodes Public Trust in Leaders'
author: "Jonathan Koop & Zhipei Wang"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This Rmd-file aims to replicate the findings from Colombatto et al. (2023) who published the finding people in Australia, Canada, the United Kingdom and the United States counterintuitively trusted leaders with redistributive policies more than those with such that are of nationalistic nature. They mention to have conducted seven experiments with a total of $N=4,215$ adults leading to these findings. These experiments varied concerning their design, with nationally representative samples, expert and non-expert forecasts, and studies examining trust in the context of different diseases such as COVID-19 and H5N1 avian influenza.

In this project, we aim to replicate the authors' findings from Study 1 and 2. We additionally ran all analysis code provided by the authors and checked them for validity. This can be done by opening the respective Rmd-file in the Original_Analyses folder.

# 1. Preparations

## 1.1 Loading Required Packages (through pacman for reproducibility)

```{r}
if (!require("pacman")) install.packages("pacman"); library("pacman")
p_load("tidyverse", "knitr", "osfr")
```

## 1.2 Loading the Data

```{r}
if (length(dir("Original_Analysis/")) == 0) { # If no files exist in Subfolder, download
  osf_retrieve_node("q6ej4") %>% # retrieve repository from osf
    osf_ls_files() %>% # list files in repository
    slice(c(4, 6)) %>% # only keep files 4 and 6 (Study 1 and 2)
    osf_download(path = "Original_Analysis/") # Download files in Original_Analysis/
} else {} # if files already exist, do nothing

data_s1 <- read.csv("Original_Analysis/S1 - Trust/S1 - Data.csv")
data_s2 <- read.csv("Original_Analysis/S2 - Trust YouGov/S2 - Data.csv")
```

## 1.3 Running `sessionInfo` (for Reproducibility)
```{r}
sessionInfo()
```

# 2. Study 1

## 2.1 Descriptive Statistics

### 2.1.1 Sample Size

According to Colombatto et al. (2023), 2,000 participants were recruited with 500 from each country. More precise numbers are not given.

```{r}
participants <- data_s1 %>%
  filter(duplicate_IP != 1) %>% # remove duplicate cases
  group_by(country) %>% # group data by region
  summarize(participants = n()) # count the number of participants in each country

kable(participants) # print the counts of participants by country
```

Summarizing the given data set, excluding duplicate entries, at first sight, shows that this is quite plausible as the numbers of participants lie near 500 for all countries. At second sight, however, it appears that `r participants$participants[participants$country == "Canada"]` of the participants lived in Canada which is higher than the authors mentioned. A plausible explanation for this may be that some of the participants recruited for some other countries (in particular the United States) may have moved to Canada.

### 2.1.2 Excluded Respondents

Next, the authors mention that based on multiple criteria outlined and checked below:

*(1) 46 respondents for taking the survey more than once*

```{r}
excluded_morethanonce <- data_s1 %>%
  filter(duplicate_IP == 1) # save duplicate cases

nrow(excluded_morethanonce) # print the number of duplicate cases
```

This aligns with the data.

*(2) 245 respondents for failing one or both attention checks*

```{r}
excluded_attcheck <- data_s1 %>%
  filter(duplicate_IP != 1) %>% # remove duplicate cases
  filter(att_check1 != "TikTok" |
         att_check2 != "Roses can suffer with pests like aphids and blackfly") # remove participants who failed one or more attention checks

nrow(excluded_attcheck) # Excluding duplicate cases, print the number of participants who failed one or more attention checks
```

Excluding duplicate entries, this also aligns with the given data.

*(3) 2 respondents reported living in another country than Australia, Canada, the United Kingdom, and the United States*

```{r}
excluded_country <- data_s1 %>%
  filter(duplicate_IP != 1) %>% # remove duplicate cases
  filter(country == "Other") # remove participants who reported living in a different country from that of intended recruitment

nrow(excluded_country) # print the number of participants who reported living in a different country from that of intended recruitment
```

This aligns with the data as well.

*(4) 101 failed a comprehension check*

```{r}
excluded_compcheck1 <- data_s1 %>%
  filter(duplicate_IP != 1) %>% # remove duplicate cases
  filter(comp_check != "How much I trusted the mayor") # remove participants who failed the comprehension check

nrow(excluded_compcheck1) # print the number of participants who failed the comprehension check
```

Out of all non-duplicate entries, the code above shows that `r nrow(excluded_compcheck1)` respondents failed the attention check, which does not align with the number given by the authors. However, it is also plausible that the authors referred to respondents who were not removed for other reasons listed before (i.e., (1) to (3)).

```{r}
# remove duplicate cases, remove participants who failed one or more attention checks or the comprehension check, who reported living in a different country from that of intended recruitment
excluded_compcheck2 <- data_s1 %>%
  filter(duplicate_IP != 1,
         att_check1 == "TikTok",
         att_check2 == "Roses can suffer with pests like aphids and blackfly",
         country == survey_c,
         comp_check != "How much I trusted the mayor") 

nrow(excluded_compcheck2) # print the number of participants who failed the comprehension check, along with other exclusion criteria
```

This way leads to the provided `r nrow(excluded_compcheck2)` respondents.

### 2.1.3 Characteristics of the Analysis Sample

Following this specification, we exclude these individuals from the sample through `dplyr`'s `filter` function 
```{r}
data_s1_sample <- data_s1 %>%
  # exclude individuals who took the survey more than once (either duplicate id or ip, not specified but 46x IP==1)
  # remove participants who failed one or more attention checks or the comprehension check, who reported living in a different country from that of intended recruitment
  filter(duplicate_IP != 1,
         att_check1 == "TikTok",
         att_check2 == "Roses can suffer with pests like aphids and blackfly",
         country == survey_c,
         comp_check == "How much I trusted the mayor") %>%
  
  # Dependent Variable Avg of both trust questions
  mutate(trust_comb = (trust_1 + trust_2)/2, # form trust score as avg of both trust items
         cond = as.factor(cond), # convert cond into a factor variable
         gender = dplyr::recode(gender, "Man" = "male",
                         "Woman" = "female",
                         "Some other way" = "other"), # recode gender
         race = as.factor(race), # convert race into a factor variable
         education = as.factor(education), # convert education into a factor variable
         country = as.factor(country)) # convert country into a factor variable

kable(table(data_s1_sample$gender), col.names = c("Gender", "Frequency")) # print the counts of genders
round(mean(data_s1_sample$age, na.rm = TRUE), 2) # print the mean age
```


## 2.2 Regression Analysis

Next, we ran the regression analysis with all the control variables mentioned by the authors. Unfortunately, no information was given about how these variables were recoded.

Colombatto et al. published several regression analyses for the first study, which will be went through followingly step by step:

### (1) Linear Regression of Analysis Sample: Effect of Condition on Trust (published statistics: $b=1.54$, $SE=0.06$, $t=24.70$ $p<0.001$, 95\%-CI = [1.42, 1.66])

After estimating a model with fixed and random effects the authors run a linear regression model with all control variables concluding with the following statement:
"As shown in Figure 1a, leaders who endorsed vaccine redistribution were trusted more than those who endorsed vaccine nationalism (b = 1.54, SE = 0.06, t =24.70, p < .001, 95% confidence interval (CI) = [1.42, 1.66]; mean trust for redistribution leader = 5.02 on a scale from 1 to 7, SE = 0.10 vs. mean trust for nationalism leader = 3.48, SE = 0.10)."

We now estimated the model drawing upon the description of the data in the paper, the preregistration and the questionnaire, which led to the following results:

```{r}
model_s1_1 <- lm(trust_comb ~ cond + support + gender + age + race + education + ses2 + politics + religious + country, data = data_s1_sample) 
# build the model with cond (type of leader) and other demographic characteristics 

kable(summary(model_s1_1)$coefficients) # print the summary of the model coefficients

round(confint(model_s1_1, "condRedistribution", level = 0.95), 2) # print the 95% confidence interval for the coefficient of the dummy variable "condRedistribution", round to 2 decimal points
```
Running the regression analysis, one can observe that there seems to be an issue with the levels of the $race$ variable, which overloads the model with variables due to its dummy coding. Therefore, we will code it to a binary variable which is a common procedure in research.

```{r}
data_s1_sample <- data_s1_sample %>%
  mutate(
    race = if_else(race == "White", "White", "Other") # recode race to a binary variable
    )
```

And then rerun the regression analysis:

```{r}
model_s1_2 <- lm(trust_comb ~ cond + support + gender + age + race + education + ses2 + politics + religious, data = data_s1_sample) 
# build the model with cond (type of leader) and other demographic characteristics

kable(summary(model_s1_2)$coefficients) # print the summary of the model coefficients

round(confint(model_s1_2, "condRedistribution", level = 0.95), 2) # print the 95% confidence interval for the coefficient of the dummy variable "condRedistribution", round to 2 decimal points
```
Still, the given statistics do not match those retrieved from this analysis. However, the values are very close to what the authors provided and are significant.

After inspecting Colombatto et al.'s code, we recognized they converted education to a continuous variable. We deem this transformation slightly problematic since - even though *education* has 8 levels, the levels are not necessarily equally spaced, which is required for treating the data as interval scaled. After applying this transformation we received the same results as those published by the authors:

```{r}
data_s1_sample <- data_s1_sample %>%
  mutate(education_num = dplyr::recode(education, "Some elementary school / primary school" = 1,
                             "Completed elementary school / primary school" = 2, 
                             "Some high school / secondary school" = 3, 
                             "Completed high school / secondary school" = 4, 
                             "Some college / undergraduate degree" = 5, 
                             "Completed college / undergraduate degree" = 6, 
                             "Some advanced postgraduate degree" = 7, 
                             "Completed advanced postgraduate degree " = 8,
                             "Completed advanced postgraduate degree" = 8))
# recode education as a numerical variable 

model_s1_3 <- lm(trust_comb ~ cond + support + gender + age + race + education_num + ses2 + politics + religious, data = data_s1_sample) 
# build the model with cond (type of leader) and other demographic characteristics

kable(summary(model_s1_3)$coefficients) # print the summary of the model coefficients

round(confint(model_s1_3, "condRedistribution", level = 0.95), 2) # print the 95% confidence interval for the coefficient of the dummy variable "condRedistribution", round to 2 decimal points
```
This leads to the same results.

### (2) Regression Analysis Only Applying Exclusion Criteria 1 and 3 (published statistics: $b = 1.48$, $SE = 0.06$, $t = 25.89$, $p < .001$, 95\%-CI = [1.37, 1.59])
```{r}
data_s1_sample_2 <- data_s1 %>%
  # exclude individuals who took the survey more than once (either duplicate id or ip, not specified but 46x IP==1)
  filter(duplicate_IP != 1,
         country == survey_c) %>% # remove participants who reported living in a different country from that of intended recruitment
  
  # Dependent Variable Avg of both trust questions
  mutate(trust_comb = (trust_1 + trust_2)/2, # form trust score as avg of both trust items
         cond = as.factor(cond), # make cond (type of leader) a factor variable
         gender = as.factor(gender), # make gender a factor variable
         race = if_else(race == "White", "White", "Other"), # make race a binary variable
         education = as.factor(education), # make education a factor variable
         education_num = dplyr::recode(education, "Some elementary school / primary school" = 1,
                             "Completed elementary school / primary school" = 2,
                             "Some high school / secondary school" = 3,
                             "Completed high school / secondary school" = 4,
                             "Some college / undergraduate degree" = 5,
                             "Completed college / undergraduate degree" = 6,
                             "Some advanced postgraduate degree" = 7,
                             "Completed advanced postgraduate degree " = 8,
                             "Completed advanced postgraduate degree" = 8), # also make a numerical education variable
         country = as.factor(country)) # make country a factor variable

# With categorical education

# build the model with cond (type of leader) and other demographic characteristics, with education being a categorical variable
model_s1_4 <- lm(trust_comb ~ cond + support + gender + age + race + education + ses2 + politics + religious, data = data_s1_sample_2) 
kable(summary(model_s1_4)$coefficients) # print the summary of the model coefficients
round(confint(model_s1_4, "condRedistribution", level = 0.95), 2) # print the 95% confidence interval for the coefficient of the dummy variable "condRedistribution", round to 2 decimal points

# With continuous education

# build the model with cond (type of leader) and other demographic characteristics, with education being a numerical variable
model_s1_5 <- lm(trust_comb ~ cond + support + gender + age + race + education_num + ses2 + politics + religious, data = data_s1_sample_2) 
kable(summary(model_s1_5)$coefficients) # print the summary of the model coefficients
round(confint(model_s1_5, "condRedistribution", level = 0.95), 2) # print the 95% confidence interval for the coefficient of the dummy variable "condRedistribution", round to 2 decimal points
```
Once again, after recoding education to a continuous variable, the results match. When keeping education categorical, the statistics again slightly deviate from the published but the effect remains significant and *b*- and *t*-values are very similar.


### (3) Regression Analysis for Interaction Between Condition and Country (published statistics: all interactions $b < 0.19$, $p > 0.281$)

```{r}
# build the model with cond and country and an iteraction between cond and country
model_s1_6 <- lm(trust_comb ~ cond * country, data_s1_sample)

kable(summary(model_s1_6)$coefficients) # print the summary of the model coefficients
```
The results here do not match, since  even though, in fact all $b$-values are below 0.19, the p-value of the redistributive condition with respondents living in the United Kingdom is lower than 0.281. The reason for this difference is that we did not specify a reference category for either of the two variables. One step further, the authors' statement that there are all interactions have p-values above 0.281 is not true without specifying the chosen reference category.

In fact, the authors chose the United States as reference category. This will be applied to validate the results.

```{r}
# recode country so that United States is the reference category
data_s1_sample$country <- factor(data_s1_sample$country, levels = c("United States", "Australia", 
                                               "Canada", "United Kingdom"))

# build the model with cond and country and an iteraction between cond and country, with United States being the reference category
model_s1_7 <- lm(trust_comb ~ cond * country, data_s1_sample)

kable(summary(model_s1_7)$coefficients) # print the summary of the model coefficients
```
Now the output matches the reported results.

### (4) Regression Analysis Without Control Variables (published statistics: $b = 1.54$, $SE = 0.06$, $t = 24.60$, $p < .001$, 95% CI = [1.41, 1.66]))

```{r}
# build the model with cond (type of leader) only
model_s1_8 <- lm(trust_comb ~ cond, data = data_s1_sample) 
kable(summary(model_s1_8)$coefficients) # print the summary of the model coefficients
round(confint(model_s1_8, "condRedistribution", level = 0.95), 2) # print the 95% confidence interval for the coefficient of the dummy variable "condRedistribution", round to 2 decimal points
```

Also here the results match.


## 2.3 Assumption checking (for first reproduced full model)
### (1) Linear Regression of Analysis Sample: Effect of Condition on Trust (published statistics: $b=1.54$, $SE=0.06$, $t=24.70$ $p<0.001$, 95\%-CI = [1.42, 1.66])
```{r }
plot(model_s1_3)
```


Assumption 1: Independence of observations (i.e., independence of residuals)
This is questionable as the Residual vs Fitted plot shows a pattern where there are two clusters of residuals and the spread of them doesn't look random.

Assumption 2: Linearity of the Data
Looking again at the Residual vs Fitted plot, the red line is approximately horizontal at zero, meaning that this assumption should be met.

Assumption 3: Homoscedasticity
Looking at the scale-location plot, the red line is approximately horizontal but the spread of the points looks questionable, which means this assumption may not be met.

Assumption 4: No multicollinearity
This can be checked by looking at the correlation matrix or calculating the variance inflation factors (VIF). The correlations between variables are not high and the VIFs are lower than 2, so there's no multicollinearity.

```{r}
data_s1_sample %>%
  select(trust_comb, support, age, education_num, ses2, politics, religious) %>%
  na.omit() %>%
  cor() %>%
  round(2)
```


```{r warning=FALSE, message=FALSE}
library(car)
vif(model_s1_3)
```


Assumption 5: There should be no significant outliers, high leverage points or highly influential points.
It can be shown from the residual vs leverage plot and the cook's distance plot that there are a few potential outliers and high influential points, but there were no red dashed lines (thresholds for determining if they are extreme) in both plots, so this assumption should be met.
```{r}
plot(model_s1_3, 4)
```


Assumption 6: The residuals (errors) are approximately normally distributed. 
The normal Q-Q plot shows that the residuals are approximately normally distributed with only some deviations at both tails.

```{r}
# remove the objects in the r environment except for the two datasets
rm(list = ls()[!ls() %in% c("data_s1", "data_s2")])
```


# 3. Study 2

In the second study, similar analyses are conducted using a different probability-based sample from the United States. Like in the previous chapter, we will also try to verify whether the code reflects the analyses as described in the code.

## 3.1 Descriptive Statistics

### 3.1.1 Sample Size
```{r}
nrow(data_s2) # check the sample size of study 2
```
The number of observations in the given data matches the mentioned sample size in the paper.

### 3.1.2 Excluded Respondents

*(1) 247 respondents failed one or both attention checks*

```{r}
excluded_attcheck <- data_s2 %>%
  filter(consent == "Yes") %>% # remove the participants who didn't consent
  filter(att_check1 != "TikTok" |
         att_check2 != "Roses can suffer with pests like aphids and blackfly") # remove the participants who failed one or two attention checks

nrow(excluded_attcheck) # print the number of participants who consented, or failed one or two attention checks
```

Only looking at those respondents with consent this aligns with the data.

*(2) 56 respondents failed the comprehension check*

```{r}
excluded_compcheck <- data_s2 %>%
  filter(consent == "Yes", # remove the participants who didn't consent
         comp_check != "How much I trusted the mayor") # remove the participants who failed the comprehension check

nrow(excluded_compcheck) # print the number of participants who consented, or failed the comprehension check

excluded_compcheck2 <- data_s2 %>%
  filter(consent == "Yes", # remove the participants who didn't consent
         att_check1 == "TikTok" &
         att_check2 == "Roses can suffer with pests like aphids and blackfly", # remove the participants who failed one or two attention checks
         comp_check != "How much I trusted the mayor") # remove the participants who failed the comprehension check

nrow(excluded_compcheck2) # print the number of participants who consented, but failed one or two attention checks, or failed the comprehension check
```

When looking at all respondents with consent, actually `r nrow(excluded_compcheck)` respondents failed the comprehension check. Looking at respondents who were not excluded for other reasons, we receive the given number of `r nrow(excluded_compcheck2)`

*(3) 2 respondents did not agree to the consent form*

```{r}
excluded_consent <- data_s2 %>%
  filter(consent == "No") # select the participants who didn't consent

nrow(excluded_consent) # print the number of participants who didn't consent
```

This matches the number given in the paper.

### 3.1.3 Characteristics of the Analysis Sample

```{r}
data_s2_sample <- data_s2 %>%
  filter(consent == "Yes", # remove the participants who didn't consent
         att_check1 == "TikTok" &
         att_check2 == "Roses can suffer with pests like aphids and blackfly", # remove the participants who failed one or two attention checks
         comp_check == "How much I trusted the mayor") %>% # remove the participants who failed the comprehension check
  
  # Dependent Variable Avg of both trust questions
  mutate(trust_comb = (trust_1 + trust_2)/2, # form trust score as avg of both trust items
         cond = as.factor(cond), # make cond a factor variable
         gender = dplyr::recode(gender, "Man" = "male",
                         "Woman" = "female",
                         "Some other way" = "other"), # recode gender
         race = if_else(race == "White", "White", "Other"), # make race a binary variable
         education = as.factor(education), # make education a factor variable
         education_num = dplyr::recode(education, 
                               "Some elementary school / primary school" = 1,
                               "Completed elementary school / primary school" = 2, 
                               "Some high school / secondary school" = 3, 
                               "Completed high school / secondary school" = 4, 
                               "Some college / undergraduate degree" = 5, 
                               "Completed college / undergraduate degree" = 6, 
                               "Some advanced postgraduate degree" = 7,
                               "Completed advanced postgraduate degree" = 8)) # also make a numerical education variable


kable(table(data_s2_sample$gender)) # print counts of genders
round(mean(data_s2_sample$age, na.rm = TRUE), 2) # print mean age
```

## 3.2 Regression Analysis

### (1) Linear Regression of Analysis Sample: Effect of Condition on Trust (published statistics: $b=1.26$, $SE=0.16$, $t=8.06$ $p<0.001$, 95\%-CI = [0.95, 1.56])

```{r}
# With education as numerical

# build the model with cond (type of leader) and other demographic characteristics, with education being a numerical variable
model_s2_1 <- lm(trust_comb ~ cond + support + gender + age + race + education_num + ses2 + politics + religious, data = data_s2_sample) 

kable(summary(model_s2_1)$coefficients) # print the summary of the model coefficients
round(confint(model_s2_1, "condRedistribution", level = 0.95), 2) # print the 95% confidence interval for the coefficient of the dummy variable "condRedistribution", round to 2 decimal points

# With education as categorical

# build the model with cond (type of leader) and other demographic characteristics, with education being a categorical variable
model_s2_2 <- lm(trust_comb ~ cond + support + gender + age + race + education + ses2 + politics + religious, data = data_s2_sample) 

kable(summary(model_s2_2)$coefficients) # print the summary of the model coefficients
round(confint(model_s2_2, "condRedistribution", level = 0.95), 2) # print the 95% confidence interval for the coefficient of the dummy variable "condRedistribution", round to 2 decimal points
```

This leads to the same results.

### (2) Regression Analysis Without Exclusion Criteria (published statistics: $b = 0.98$, $SE = 0.12$, $t = 8.16$, $p < .001$, 95\%
CI = [0.75, 1.22])
```{r}
data_s2_sample_2 <- data_s2 %>%
  # exclude individuals who took the survey more than once (either duplicate id or ip, not specified but 46x IP==1)
  filter(consent == "Yes") %>% # remove the participants who didn't consent
  
  # Dependent Variable Avg of both trust questions
  mutate(trust_comb = (trust_1 + trust_2)/2, # form trust score as avg of both trust items
         cond = as.factor(cond), # make cond a factor variable
         gender = dplyr::recode(gender, "Man" = "male",
                         "Woman" = "female",
                         "Some other way" = "other"), # recode gender
         race = if_else(race == "White", "White", "Other"), # make race a binary variable
         education = as.factor(education), # make education a categorical variable
         education_num = dplyr::recode(education, 
                               "Some elementary school / primary school" = 1,
                               "Completed elementary school / primary school" = 2, 
                               "Some high school / secondary school" = 3, 
                               "Completed high school / secondary school" = 4, 
                               "Some college / undergraduate degree" = 5, 
                               "Completed college / undergraduate degree" = 6, 
                               "Some advanced postgraduate degree" = 7,
                               "Completed advanced postgraduate degree" = 8)) # also make a numerical variable education


# With education as numerical

# build the model with cond (type of leader) and other demographic characteristics, with education being a numerical variable
model_s2_2 <- lm(trust_comb ~ cond + support + gender + age + race + education_num + ses2 + politics + religious, data = data_s2_sample_2) 

kable(summary(model_s2_2)$coefficients) # print the summary of the model coefficients
round(confint(model_s2_2, "condRedistribution", level = 0.95), 2) # print the 95% confidence interval for the coefficient of the dummy variable "condRedistribution", round to 2 decimal points

# With education as categorical

# build the model with cond (type of leader) and other demographic characteristics, with education being a categorical variable
model_s2_3 <- lm(trust_comb ~ cond + support + gender + age + race + education + ses2 + politics + religious, data = data_s2_sample_2) 

kable(summary(model_s2_3)$coefficients) # print the summary of the model coefficients
round(confint(model_s2_3, "condRedistribution", level = 0.95), 2) # print the 95% confidence interval for the coefficient of the dummy variable "condRedistribution", round to 2 decimal points
```
The results match again, when looking at education numerically. Dummy coding education again leads to very similar results.


### (3) Regression Analysis Without Control Variables (published statistics: $b = 1.28$, $SE = 0.16$, $t = 8.25$, $p < .001$, 95% CI = [0.98, 1.59]))

```{r}

# build the model with cond (type of leader) only
model_s2_3 <- lm(trust_comb ~ cond, data = data_s2_sample) 
kable(summary(model_s2_3)$coefficients) # print the summary of the model coefficients
round(confint(model_s2_3, "condRedistribution", level = 0.95), 2) # print the 95% confidence interval for the coefficient of the dummy variable "condRedistribution", round to 2 decimal points
```

Once again we retrieve the same results as reported by Colombatto et al.



## 3.3 Assumption checking (for first reproduced full model)
### (1) Linear Regression of Analysis Sample: Effect of Condition on Trust (published statistics: $b=1.26$, $SE=0.16$, $t=8.06$ $p<0.001$, 95\%-CI = [0.95, 1.56])
```{r}
plot(model_s2_1)
```


Assumption 1: Independence of observations (i.e., independence of residuals)
This is questionable as the Residual vs Fitted plot shows a pattern where there are two clusters of residuals and the spread don't look completely random.

Assumption 2: Linearity of the Data
Looking again at the Residual vs Fitted plot, the red line is approximately horizontal at zero, meaning that this assumption should be met.

Assumption 3: Homoscedasticity
Looking at the scale-location plot, the red line is approximately horizontal but the spread of the points looks questionable, which means this assumption may not be met.

Assumption 4: No multicollinearity
This can be checked by looking at the correlation matrix or calculating the variance inflation factors (VIF). The correlations between variables are not high and the VIFs are lower than 2, so there's no multicollinearity.

```{r}
data_s2_sample %>%
  select(trust_comb, support, age, education_num, ses2, politics, religious) %>%
  na.omit() %>%
  cor() %>%
  round(2)
```


```{r warning=FALSE, message=FALSE}
vif(model_s2_1)
```


Assumption 5: There should be no significant outliers, high leverage points or highly influential points.
It can be shown from the residual vs leverage plot and the cook's distance plot that there are a few potential outliers and high influential points, but there were no red dashed lines (thresholds for determining if they are extreme) in both plots, so this assumption should be met.
```{r}
plot(model_s2_1, 4)
```


Assumption 6: The residuals (errors) are approximately normally distributed. 
The normal Q-Q plot shows that the residuals are approximately normally distributed with only some deviations at both tails.

